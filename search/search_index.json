{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"deck.gl-raster \u00b6 deck.gl layers and WebGL modules for client-side satellite imagery processing on the GPU. Landsat Modified Soil Adjusted Vegetation Index over the Grand Canyon and Kaibab Plateau, with the cfastie colormap . Overview \u00b6 deck.gl is a great geospatial rendering engine for the browser. deck.gl layers are designed to be composable and easy to extend. As such, small variations of the pre-built layers can do amazing new things, while not being fit for inclusion in the standard layer library. This repository contains deck.gl layers and reusable WebGL modules for rendering and computation on rasters, especially satellite imagery. Install \u00b6 yarn add @kylebarron/deck.gl-raster Full Documentation","title":"Home"},{"location":"#deckgl-raster","text":"deck.gl layers and WebGL modules for client-side satellite imagery processing on the GPU. Landsat Modified Soil Adjusted Vegetation Index over the Grand Canyon and Kaibab Plateau, with the cfastie colormap .","title":"deck.gl-raster"},{"location":"#overview","text":"deck.gl is a great geospatial rendering engine for the browser. deck.gl layers are designed to be composable and easy to extend. As such, small variations of the pre-built layers can do amazing new things, while not being fit for inclusion in the standard layer library. This repository contains deck.gl layers and reusable WebGL modules for rendering and computation on rasters, especially satellite imagery.","title":"Overview"},{"location":"#install","text":"yarn add @kylebarron/deck.gl-raster Full Documentation","title":"Install"},{"location":"colormaps/","text":"Colormaps \u00b6 deck.gl-raster includes some public colormaps in the Github repository. These generally come from rio-tiler , which were themselves mostly derived from Matplotlib. A few custom colormaps that are commonly-used with raster data are included. To use them, you can load the PNG via the jsdelivr CDN, e.g.: https://cdn.jsdelivr.net/gh/kylebarron/deck.gl-raster/assets/colormaps/{colormap_name}.png Included Colormaps \u00b6 Referencess \u00b6 Matplotlib: matplotlib.org/3.1.0/tutorials/colors/colormaps.html cfastie: publiclab.org/notes/cfastie/08-26-2014/new-ndvi-colormap rplumbo: cogeotiff/rio-tiler!90 schwarzwald: soliton.vm.bytemark.co.uk/pub/cpt-city/wkp/schwarzwald/tn/wiki-schwarzwald-cont.png.index.html","title":"Colormaps"},{"location":"colormaps/#colormaps","text":"deck.gl-raster includes some public colormaps in the Github repository. These generally come from rio-tiler , which were themselves mostly derived from Matplotlib. A few custom colormaps that are commonly-used with raster data are included. To use them, you can load the PNG via the jsdelivr CDN, e.g.: https://cdn.jsdelivr.net/gh/kylebarron/deck.gl-raster/assets/colormaps/{colormap_name}.png","title":"Colormaps"},{"location":"colormaps/#included-colormaps","text":"","title":"Included Colormaps"},{"location":"colormaps/#referencess","text":"Matplotlib: matplotlib.org/3.1.0/tutorials/colors/colormaps.html cfastie: publiclab.org/notes/cfastie/08-26-2014/new-ndvi-colormap rplumbo: cogeotiff/rio-tiler!90 schwarzwald: soliton.vm.bytemark.co.uk/pub/cpt-city/wkp/schwarzwald/tn/wiki-schwarzwald-cont.png.index.html","title":"Referencess"},{"location":"overview/","text":"Overview \u00b6 This page provides a high-level overview of how the package works, and provides helpful context for further documentation. Currently, this package emphasizes Fetching imagery \u00b6 Control over backend","title":"Overview"},{"location":"overview/#overview","text":"This page provides a high-level overview of how the package works, and provides helpful context for further documentation. Currently, this package emphasizes","title":"Overview"},{"location":"overview/#fetching-imagery","text":"Control over backend","title":"Fetching imagery"},{"location":"examples/raster-layer-md/","text":"RasterLayer Interactive Example \u00b6","title":"RasterLayer"},{"location":"examples/raster-layer-md/#rasterlayer-interactive-example","text":"","title":"RasterLayer Interactive Example"},{"location":"examples/raster-mesh-layer-md/","text":"RasterMeshLayer Interactive Example \u00b6","title":"RasterMeshLayer"},{"location":"examples/raster-mesh-layer-md/#rastermeshlayer-interactive-example","text":"","title":"RasterMeshLayer Interactive Example"},{"location":"layers/raster-layer/","text":"RasterLayer \u00b6 The RasterLayer is a subclass of deck.gl's built-in BitmapLayer that enables image operations on satellite image bands. All image operations are done on the GPU for best performance. You can combine RGB bands in true color or false color manners, or create a spectral index and apply a colormap. With true color imagery, you can apply pansharpening from a panchromatic band. If an operation hasn't been implemented yet, it's relatively easy to add your own operations. Props \u00b6 modules \u00b6 array : default [] An array of WebGL modules that define the pipeline to be run on the GPU. Note that the order of modules is important, since modules are applied in the same order. If you wanted to create NDVI with a colormap, you'd want modules to be something like: [ combineBands , normalizedDifference , colormap ]; If the order were instead: [ combineBands , colormap , normalizedDifference ]; you'd likely see an unintelligible grayscale image. That's because the colormap step first transforms the internal image object from one dimension to three, and then the normalizedDifference step takes the first two dimensions of the colormapped image and transforms back to a single dimension. That one dimension will be rendered as grayscale. images \u00b6 Object : default {} An object containing image data for use in the WebGL modules. The object's keys should be strings corresponding to the desired module's property name, and the values should be an object containing Image data or Texture2D objects, or an array of these objects. For example, say I have two independent images representing the near-infrared (NIR), and red image bands from a satellite. I'd pass an images object like the following: import GL from \"@luma.gl/constants\" ; const images = { imageBands : [ // NIR band { data : ImageData // Use format: GL.LUMINANCE when the ImageData only has one band/channel // Otherwise use GL.RGB or GL.RGBA format : GL . LUMINANCE }, // red band { data : ImageData format : GL . LUMINANCE } ] } If I additionally wanted to apply a pansharpening step, for example, I'd add a new key named imagePan in the images object, and include the pansharpenBrovey module in the modules array above. Note that when image data is passed as an object, it is internally passed on to Luma.gl's Texture2D . For full control over rendering, consult its documentation for additional texture parameters. Any image data should be passed through images rather than through moduleProps , as the former will provide better performance and allow you to not touch the underlying GL context. moduleProps \u00b6 Object : default {} An object containing non-image properties to be passed to modules. For example, if pansharpenBrovey is included in your modules list and you wanted to change panWeight , you would pass moduleProps as: moduleProps : { panWeight : 1.0 ; } Refer to the WebGL Modules documentation to see available props exposed by each module. BitmapLayer Props \u00b6 This layer inherits all props from the built-in deck.gl BitmapLayer .","title":"RasterLayer"},{"location":"layers/raster-layer/#rasterlayer","text":"The RasterLayer is a subclass of deck.gl's built-in BitmapLayer that enables image operations on satellite image bands. All image operations are done on the GPU for best performance. You can combine RGB bands in true color or false color manners, or create a spectral index and apply a colormap. With true color imagery, you can apply pansharpening from a panchromatic band. If an operation hasn't been implemented yet, it's relatively easy to add your own operations.","title":"RasterLayer"},{"location":"layers/raster-layer/#props","text":"","title":"Props"},{"location":"layers/raster-layer/#modules","text":"array : default [] An array of WebGL modules that define the pipeline to be run on the GPU. Note that the order of modules is important, since modules are applied in the same order. If you wanted to create NDVI with a colormap, you'd want modules to be something like: [ combineBands , normalizedDifference , colormap ]; If the order were instead: [ combineBands , colormap , normalizedDifference ]; you'd likely see an unintelligible grayscale image. That's because the colormap step first transforms the internal image object from one dimension to three, and then the normalizedDifference step takes the first two dimensions of the colormapped image and transforms back to a single dimension. That one dimension will be rendered as grayscale.","title":"modules"},{"location":"layers/raster-layer/#images","text":"Object : default {} An object containing image data for use in the WebGL modules. The object's keys should be strings corresponding to the desired module's property name, and the values should be an object containing Image data or Texture2D objects, or an array of these objects. For example, say I have two independent images representing the near-infrared (NIR), and red image bands from a satellite. I'd pass an images object like the following: import GL from \"@luma.gl/constants\" ; const images = { imageBands : [ // NIR band { data : ImageData // Use format: GL.LUMINANCE when the ImageData only has one band/channel // Otherwise use GL.RGB or GL.RGBA format : GL . LUMINANCE }, // red band { data : ImageData format : GL . LUMINANCE } ] } If I additionally wanted to apply a pansharpening step, for example, I'd add a new key named imagePan in the images object, and include the pansharpenBrovey module in the modules array above. Note that when image data is passed as an object, it is internally passed on to Luma.gl's Texture2D . For full control over rendering, consult its documentation for additional texture parameters. Any image data should be passed through images rather than through moduleProps , as the former will provide better performance and allow you to not touch the underlying GL context.","title":"images"},{"location":"layers/raster-layer/#moduleprops","text":"Object : default {} An object containing non-image properties to be passed to modules. For example, if pansharpenBrovey is included in your modules list and you wanted to change panWeight , you would pass moduleProps as: moduleProps : { panWeight : 1.0 ; } Refer to the WebGL Modules documentation to see available props exposed by each module.","title":"moduleProps"},{"location":"layers/raster-layer/#bitmaplayer-props","text":"This layer inherits all props from the built-in deck.gl BitmapLayer .","title":"BitmapLayer Props"},{"location":"layers/raster-mesh-layer/","text":"RasterMeshLayer \u00b6 Landsat infrared false-color composite of Mt. St. Helens. Overview \u00b6 The RasterMeshLayer is a subclass of deck.gl's built-in SimpleMeshLayer that enables image operations on satellite image bands, overlaid onto 3D terrain . All image operations are done on the GPU for best performance. You can combine RGB bands in true color or false color manners, or create a spectral index and apply a colormap. With true color imagery, you can apply pansharpening from a panchromatic band. If an operation hasn't been implemented yet, it's relatively easy to add your own operations. Props \u00b6 modules \u00b6 See RasterLayer modules for documentation. images \u00b6 See RasterLayer images for documentation. moduleProps \u00b6 See RasterLayer moduleProps for documentation. SimpleMeshLayer Props \u00b6 This layer inherits all props from the built-in deck.gl SimpleMeshLayer . E.g. provide the terrain object through the mesh prop. The SimpleMeshLayer 's texture prop is replaced by the above custom props.","title":"RasterMeshLayer"},{"location":"layers/raster-mesh-layer/#rastermeshlayer","text":"Landsat infrared false-color composite of Mt. St. Helens.","title":"RasterMeshLayer"},{"location":"layers/raster-mesh-layer/#overview","text":"The RasterMeshLayer is a subclass of deck.gl's built-in SimpleMeshLayer that enables image operations on satellite image bands, overlaid onto 3D terrain . All image operations are done on the GPU for best performance. You can combine RGB bands in true color or false color manners, or create a spectral index and apply a colormap. With true color imagery, you can apply pansharpening from a panchromatic band. If an operation hasn't been implemented yet, it's relatively easy to add your own operations.","title":"Overview"},{"location":"layers/raster-mesh-layer/#props","text":"","title":"Props"},{"location":"layers/raster-mesh-layer/#modules","text":"See RasterLayer modules for documentation.","title":"modules"},{"location":"layers/raster-mesh-layer/#images","text":"See RasterLayer images for documentation.","title":"images"},{"location":"layers/raster-mesh-layer/#moduleprops","text":"See RasterLayer moduleProps for documentation.","title":"moduleProps"},{"location":"layers/raster-mesh-layer/#simplemeshlayer-props","text":"This layer inherits all props from the built-in deck.gl SimpleMeshLayer . E.g. provide the terrain object through the mesh prop. The SimpleMeshLayer 's texture prop is replaced by the above custom props.","title":"SimpleMeshLayer Props"},{"location":"webgl-modules/color/","text":"Color operations \u00b6 Modules to perform color operations on an existing image. colormap \u00b6 Apply a colormap onto a grayscale image. This is expected to be passed after creating a spectral index, which transforms the image bands into an index ranging from -1 to 1. Applying a colormap enables better visualization of this range of data. image Transformation \u00b6 Transforms the internal image object from 1 dimension (grayscale) to 3 dimensions (RGB). Props \u00b6 imageColormap \u00b6 Image object , required Note : make sure you pass format: GL.RGB along with the colormap image; otherwise the colormap will map the source grayscale image to a different grayscale image. The imageColormap image is expected to start as a two-dimensional image that gradually changes color horizontally through the image. The left side of the image is expected to correspond to -1, and the right is expected to correspond to 1. A collection of colormaps is hosted in the deck.gl-raster repository, but any image can be used as the colormap. The color value will be chosen horizontally. For example, for a value of 0 , the middle pixel value, horizontally, of the image will be chosen. Many colormaps are in assets/colormaps in PNG format, derived from Matplotlib and rio-tiler . To visualize them, see colormap documentation . To use them, you can use the jsdelivr CDN, e.g.: https://cdn.jsdelivr.net/gh/kylebarron/deck.gl-raster/assets/colormaps/{colormap_name}.png","title":"Color"},{"location":"webgl-modules/color/#color-operations","text":"Modules to perform color operations on an existing image.","title":"Color operations"},{"location":"webgl-modules/color/#colormap","text":"Apply a colormap onto a grayscale image. This is expected to be passed after creating a spectral index, which transforms the image bands into an index ranging from -1 to 1. Applying a colormap enables better visualization of this range of data.","title":"colormap"},{"location":"webgl-modules/color/#image-transformation","text":"Transforms the internal image object from 1 dimension (grayscale) to 3 dimensions (RGB).","title":"image Transformation"},{"location":"webgl-modules/color/#props","text":"","title":"Props"},{"location":"webgl-modules/color/#imagecolormap","text":"Image object , required Note : make sure you pass format: GL.RGB along with the colormap image; otherwise the colormap will map the source grayscale image to a different grayscale image. The imageColormap image is expected to start as a two-dimensional image that gradually changes color horizontally through the image. The left side of the image is expected to correspond to -1, and the right is expected to correspond to 1. A collection of colormaps is hosted in the deck.gl-raster repository, but any image can be used as the colormap. The color value will be chosen horizontally. For example, for a value of 0 , the middle pixel value, horizontally, of the image will be chosen. Many colormaps are in assets/colormaps in PNG format, derived from Matplotlib and rio-tiler . To visualize them, see colormap documentation . To use them, you can use the jsdelivr CDN, e.g.: https://cdn.jsdelivr.net/gh/kylebarron/deck.gl-raster/assets/colormaps/{colormap_name}.png","title":"imageColormap"},{"location":"webgl-modules/create-image/","text":"Create Image \u00b6 combineBands \u00b6 Load multiple single-band images for display or further processing. image Transformation \u00b6 Creates an internal image object where the number of dimensions is equal to the length of the imageBands array. Props \u00b6 imageBands \u00b6 Array of Image objects , required The Image objects represent the bands to combine into a single image. Note : make sure you pass format: GL.LUMINANCE along with each image; otherwise each single-band image will be loaded onto the GPU with multiple bands, wasting precious GPU memory. To create a true-color image, you would pass the red, green, and blue image bands to the imageBands prop. To create a false-color image, you would pass image bands in the desired order to the imageBands prop. For example, for a false-color agriculture image with Landsat 8 data, you would pass textures corresponding to bands 6, 5, and 2, in that order to the imageBands prop. Alternatively, combineBands can be used to assemble bands into an image for further processing, for example to create a spectral index. The spectral indices docs define which bands must be passed in which order. Note that between 1 and 4 images may be passed to imageBands . If you only want to apply a colormap onto a grayscale image, you might pass a single image texture. If you want to calculate NDVI, you need only pass two image textures. To create a true-color image you'd need three. The current maximum number of imageBands is 4. rgbaImage \u00b6 Load single multi-channel image for display or further processing. image Transformation \u00b6 Creates an internal image object where the number of dimensions is equal to the number of channels in the image. Usually 3 or 4. Props \u00b6 imageRgba \u00b6 Image object , required","title":"Create Image"},{"location":"webgl-modules/create-image/#create-image","text":"","title":"Create Image"},{"location":"webgl-modules/create-image/#combinebands","text":"Load multiple single-band images for display or further processing.","title":"combineBands"},{"location":"webgl-modules/create-image/#image-transformation","text":"Creates an internal image object where the number of dimensions is equal to the length of the imageBands array.","title":"image Transformation"},{"location":"webgl-modules/create-image/#props","text":"","title":"Props"},{"location":"webgl-modules/create-image/#imagebands","text":"Array of Image objects , required The Image objects represent the bands to combine into a single image. Note : make sure you pass format: GL.LUMINANCE along with each image; otherwise each single-band image will be loaded onto the GPU with multiple bands, wasting precious GPU memory. To create a true-color image, you would pass the red, green, and blue image bands to the imageBands prop. To create a false-color image, you would pass image bands in the desired order to the imageBands prop. For example, for a false-color agriculture image with Landsat 8 data, you would pass textures corresponding to bands 6, 5, and 2, in that order to the imageBands prop. Alternatively, combineBands can be used to assemble bands into an image for further processing, for example to create a spectral index. The spectral indices docs define which bands must be passed in which order. Note that between 1 and 4 images may be passed to imageBands . If you only want to apply a colormap onto a grayscale image, you might pass a single image texture. If you want to calculate NDVI, you need only pass two image textures. To create a true-color image you'd need three. The current maximum number of imageBands is 4.","title":"imageBands"},{"location":"webgl-modules/create-image/#rgbaimage","text":"Load single multi-channel image for display or further processing.","title":"rgbaImage"},{"location":"webgl-modules/create-image/#image-transformation_1","text":"Creates an internal image object where the number of dimensions is equal to the number of channels in the image. Usually 3 or 4.","title":"image Transformation"},{"location":"webgl-modules/create-image/#props_1","text":"","title":"Props"},{"location":"webgl-modules/create-image/#imagergba","text":"Image object , required","title":"imageRgba"},{"location":"webgl-modules/custom-modules/","text":"Custom Modules \u00b6 WebGL doesn't have a system for handling dependencies and modules, so I use a system developed by the luma.gl library. This system works by defining hooks designating where the code can be modified, and injections that insert custom code into those hooks. Currently, two such hooks exist in the RasterLayer and RasterMeshLayer , one for assembling an image and one for altering the colors in the existing image . Create color \u00b6 Mutate color \u00b6 Example: Averaging Bands \u00b6 Suppose you wanted to implement a spectral index that averages three bands. // average.js const fs = ` \\ float average_calc(vec4 image) { return (image.r + image.g + image.b) / 3.; } ` ; export default { name : \"average\" , fs , inject : { \"fs:DECKGL_MUTATE_COLOR\" : ` image = vec4(average_calc(image), 0., 0., 0.); ` , }, }; Important Notes \u00b6 Prop names must be unique.","title":"Custom Modules"},{"location":"webgl-modules/custom-modules/#custom-modules","text":"WebGL doesn't have a system for handling dependencies and modules, so I use a system developed by the luma.gl library. This system works by defining hooks designating where the code can be modified, and injections that insert custom code into those hooks. Currently, two such hooks exist in the RasterLayer and RasterMeshLayer , one for assembling an image and one for altering the colors in the existing image .","title":"Custom Modules"},{"location":"webgl-modules/custom-modules/#create-color","text":"","title":"Create color"},{"location":"webgl-modules/custom-modules/#mutate-color","text":"","title":"Mutate color"},{"location":"webgl-modules/custom-modules/#example-averaging-bands","text":"Suppose you wanted to implement a spectral index that averages three bands. // average.js const fs = ` \\ float average_calc(vec4 image) { return (image.r + image.g + image.b) / 3.; } ` ; export default { name : \"average\" , fs , inject : { \"fs:DECKGL_MUTATE_COLOR\" : ` image = vec4(average_calc(image), 0., 0., 0.); ` , }, };","title":"Example: Averaging Bands"},{"location":"webgl-modules/custom-modules/#important-notes","text":"Prop names must be unique.","title":"Important Notes"},{"location":"webgl-modules/overview/","text":"WebGL Modules \u00b6 The heart of deck.gl-raster is its WebGL modules. These building blocks give a huge amount of customizability, at the cost of a learning curve and ease of shooting yourself in the foot. A series of modules defines a pipeline : a set of transformations that provide for what computations should be done on images in the GPU. Note that it's easy to combine WebGL modules in such a way as to create an invalid pipeline , where you get WebGL errors instead of a useful result. The way to prevent these errors is to keep in mind the input dimensions and output dimensions and ensure that the output dimensions of one stage match the input dimensions of the next. For example, you couldn't run normalizedDifference followed by pansharpenBrovey because the former transforms 2 dimensions to 1 and the latter takes 4 dimensions as input. Pipeline stages \u00b6 The easiest way to think about the pipeline is in two stages, a \"create image\" step and an \"alter image\" step. Every pipeline must have a \"create image\" step; most will also have an \"alter image\" step. Create image \u00b6 Load one or more images into an internal image object. Use the modules provided in the Create Image page to load one or more images for transformations in the \"Alter image\" step. Alter image \u00b6 A set of operations to be done on the internal image object. At the end of this process, the image object will be rendered to the screen. Explore the Alter Image documentation to see available transformations, or see the Custom Modules page to write your own.","title":"Overview"},{"location":"webgl-modules/overview/#webgl-modules","text":"The heart of deck.gl-raster is its WebGL modules. These building blocks give a huge amount of customizability, at the cost of a learning curve and ease of shooting yourself in the foot. A series of modules defines a pipeline : a set of transformations that provide for what computations should be done on images in the GPU. Note that it's easy to combine WebGL modules in such a way as to create an invalid pipeline , where you get WebGL errors instead of a useful result. The way to prevent these errors is to keep in mind the input dimensions and output dimensions and ensure that the output dimensions of one stage match the input dimensions of the next. For example, you couldn't run normalizedDifference followed by pansharpenBrovey because the former transforms 2 dimensions to 1 and the latter takes 4 dimensions as input.","title":"WebGL Modules"},{"location":"webgl-modules/overview/#pipeline-stages","text":"The easiest way to think about the pipeline is in two stages, a \"create image\" step and an \"alter image\" step. Every pipeline must have a \"create image\" step; most will also have an \"alter image\" step.","title":"Pipeline stages"},{"location":"webgl-modules/overview/#create-image","text":"Load one or more images into an internal image object. Use the modules provided in the Create Image page to load one or more images for transformations in the \"Alter image\" step.","title":"Create image"},{"location":"webgl-modules/overview/#alter-image","text":"A set of operations to be done on the internal image object. At the end of this process, the image object will be rendered to the screen. Explore the Alter Image documentation to see available transformations, or see the Custom Modules page to write your own.","title":"Alter image"},{"location":"webgl-modules/pansharpen/","text":"Color operations \u00b6 Modules to perform pansharpening on an existing image. pansharpenBrovey \u00b6 Use the Weighted Brovey method to pansharpen an image. This is expected to be used on a true-color three-band RGB image. Props \u00b6 imagePan \u00b6 Texture2D , required A Texture2D object representing the panchromatic band of a satellite image scene. panWeight \u00b6 Number , default 0.2 Weight of blue band. 0.2 is suitable for Landsat imagery. To perform non-weighted Brovey pansharpening, pass panWeight: 1 . From here : Particularly for Landsat 8 imagery data, we know that the pan-band does not include the full blue band, so we take a fraction of blue (optimal weight computed in this sprint) in the pan-band and use this weight to compute the sudo_pan_band, which is a weighted average of the three bands. We then compute the ratio between the pan-band and the sudo-band and adjust each of the three bands by this ratio. Credits \u00b6 pansharpenBrovey is ported from rio-pansharpen under the MIT license.","title":"Pansharpen"},{"location":"webgl-modules/pansharpen/#color-operations","text":"Modules to perform pansharpening on an existing image.","title":"Color operations"},{"location":"webgl-modules/pansharpen/#pansharpenbrovey","text":"Use the Weighted Brovey method to pansharpen an image. This is expected to be used on a true-color three-band RGB image.","title":"pansharpenBrovey"},{"location":"webgl-modules/pansharpen/#props","text":"","title":"Props"},{"location":"webgl-modules/pansharpen/#imagepan","text":"Texture2D , required A Texture2D object representing the panchromatic band of a satellite image scene.","title":"imagePan"},{"location":"webgl-modules/pansharpen/#panweight","text":"Number , default 0.2 Weight of blue band. 0.2 is suitable for Landsat imagery. To perform non-weighted Brovey pansharpening, pass panWeight: 1 . From here : Particularly for Landsat 8 imagery data, we know that the pan-band does not include the full blue band, so we take a fraction of blue (optimal weight computed in this sprint) in the pan-band and use this weight to compute the sudo_pan_band, which is a weighted average of the three bands. We then compute the ratio between the pan-band and the sudo-band and adjust each of the three bands by this ratio.","title":"panWeight"},{"location":"webgl-modules/pansharpen/#credits","text":"pansharpenBrovey is ported from rio-pansharpen under the MIT license.","title":"Credits"},{"location":"webgl-modules/spectral-indices/","text":"Spectral Indices \u00b6 Spectral indices output a single value between -1 and 1 for each pixel. Unless you want to display a grayscale image, you probably want to apply a colormap after computing the index. normalizedDifference \u00b6 Computes the normalized difference of two bands: normalized_difference = (x - y) / (x + y) normalized_difference always uses the first two bands in the pre-assembled image as x and y respectively. To create the Normalized difference vegetation index (NDVI) , for example, you would pass the near-infrared band and the red band as the first two images to the imageBands prop in the combineBands module . enhancedVegetationIndex \u00b6 Computes the Enhanced Vegetation Index (EVI) . Layers are expected to exist as near-infrared, red, and blue bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5, 4, and 2 to the imageBands prop in the combineBands module in that order. soilAdjustedVegetationIndex \u00b6 Computes the Soil Adjusted Vegetation Index (SAVI) . Layers are expected to exist as near-infrared and red bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5 and 4 to the imageBands prop in the combineBands module in that order. modifiedSoilAdjustedVegetationIndex \u00b6 Computes the Modified Soil Adjusted Vegetation Index (MSAVI) . Layers are expected to exist as near-infrared and red bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5 and 4 to the imageBands prop in the combineBands module in that order.","title":"Spectral Indices"},{"location":"webgl-modules/spectral-indices/#spectral-indices","text":"Spectral indices output a single value between -1 and 1 for each pixel. Unless you want to display a grayscale image, you probably want to apply a colormap after computing the index.","title":"Spectral Indices"},{"location":"webgl-modules/spectral-indices/#normalizeddifference","text":"Computes the normalized difference of two bands: normalized_difference = (x - y) / (x + y) normalized_difference always uses the first two bands in the pre-assembled image as x and y respectively. To create the Normalized difference vegetation index (NDVI) , for example, you would pass the near-infrared band and the red band as the first two images to the imageBands prop in the combineBands module .","title":"normalizedDifference"},{"location":"webgl-modules/spectral-indices/#enhancedvegetationindex","text":"Computes the Enhanced Vegetation Index (EVI) . Layers are expected to exist as near-infrared, red, and blue bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5, 4, and 2 to the imageBands prop in the combineBands module in that order.","title":"enhancedVegetationIndex"},{"location":"webgl-modules/spectral-indices/#soiladjustedvegetationindex","text":"Computes the Soil Adjusted Vegetation Index (SAVI) . Layers are expected to exist as near-infrared and red bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5 and 4 to the imageBands prop in the combineBands module in that order.","title":"soilAdjustedVegetationIndex"},{"location":"webgl-modules/spectral-indices/#modifiedsoiladjustedvegetationindex","text":"Computes the Modified Soil Adjusted Vegetation Index (MSAVI) . Layers are expected to exist as near-infrared and red bands on the input image, respectively. For example, with Landsat 8 data, you would pass bands 5 and 4 to the imageBands prop in the combineBands module in that order.","title":"modifiedSoilAdjustedVegetationIndex"}]}